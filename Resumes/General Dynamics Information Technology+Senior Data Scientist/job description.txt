Type of Requisition: Regular Clearance Level Must Currently Possess: None Clearance Level Must Be Able to Obtain: None Public Trust/Other Required: NACI (T1) Job Family: Data Science and Data Engineering Job Qualifications: Skills: Analytics, Data Mining, Data Pipelines Certifications: None Experience: 5 + years of related experience US Citizenship Required: No Job Description: The Senior Data Scientist provides advanced analytical, machine learning, and data engineering support. This role combines deep expertise in predictive modeling, statistical analysis, and scalable data pipeline development to deliver production-ready solutions that drive data-informed decision-making and operational efficiency. Duties include: Design, develop, and deploy machine learning models for classification, regression, time series forecasting, and natural language processing applications to solve complex business problems. Build and optimize automated, scalable ETL/ELT pipelines using Python, SQL, and cloud-based tools to integrate, transform, and validate structured and unstructured data from diverse sources. Develop and maintain production ML systems including model deployment, monitoring, versioning, and performance tracking in collaboration with AI/ML infrastructure teams. Design, develop, and deploy interactive dashboards and data visualizations using Tableau, Power BI, or similar platforms to deliver actionable insights to technical and executive stakeholders. Perform end-to-end model development including exploratory data analysis, feature engineering, hyperparameter tuning, model validation, and documentation. Develop and maintain data pipelines and workflows using tools such as AWS services, Databricks, and GitLab CI/CD to support analytics and ML operations. Conduct data mining, cleaning, and manipulation using SQL, Python (Pandas, NumPy), or R to deliver statistical analyses, visualizations, and predictive insights. Implement data quality and validation frameworks, leveraging APIs and automated testing to ensure accuracy and completeness across systems. Translate complex business requirements into technical solutions, data models, and analytical frameworks that align with long-term technology strategy. Provide technical mentorship to team members on advanced analytics techniques, Python scripting, ML best practices, and workflow automation. Create comprehensive documentation including data dictionaries, metadata, technical specifications, and presentations for diverse audiences. Respond to urgent and ad-hoc data requests, compile reports for leadership, and coordinate collaborative research and analysis projects. Partner with cross-functional teams including data engineers, software developers, and federal stakeholders to ensure production readiness and scalability of data solutions. This position is fully remote and requires a Public Trust (or the ability to obtain it). The candidate may be required to work outside of business hours including weekends based on need. Education: Requires BS/BA degree in Data Science, Computer Science, Statistics, Mathematics, Engineering, or a related quantitative field. Master's degree preferred. Qualifications Required: At least 5 years of experience in data science, machine learning, or advanced analytics; 3 years of experience with a Master's degree. Demonstrated experience developing and deploying machine learning models using Python libraries (Scikit-learn, XGBoost, TensorFlow, PyTorch, or HuggingFace). Strong proficiency in Python and SQL for data manipulation, analysis, and pipeline development. Experience with ETL/ELT pipeline development and data engineering best practices. Demonstrated knowledge of data visualization platforms (Tableau, Power BI) and ability to translate technical insights into executive-level dashboards. Experience with cloud platforms (AWS, Databricks) and modern data infrastructure. Knowledge of statistical analysis and modeling techniques. Understanding of relational and non-relational databases (Oracle SQL, PostgreSQL, etc.). Strong version control and collaboration skills using Git (GitHub, GitLab, BitBucket). Exceptional analytical skills with strong attention to detail. Strong written and verbal communication skills with ability to present complex findings to non-technical stakeholders. Must be able to work both independently and as part of a collaborative team in a fast-paced, agile environment. Preferred: Experience with MLOps practices including model monitoring, versioning, and production deployment. Experience with CI/CD pipelines (GitLab CI/CD) for data workflows and ML operations. Knowledge of time series forecasting, natural language processing, or geospatial analysis, generative AI, or agentic AI. Experience with data orchestration and workflow automation tools. Familiarity with feature engineering, dimensionality reduction (PCA), cluster analysis, and anomaly detection techniques. Experience working with federal government data systems and compliance requirements. Background in Agile/Scrum methodologies and project management tools (Jira). Experience mentoring junior data professionals and establishing analytics best practices. The likely salary range for this position is $111,350 - $150,650. This is not, however, a guarantee of compensation or salary. Rather, salary will be set based on experience, geographic location and possibly contractual requirements and could fall outside of this range. Scheduled Weekly Hours: 40 Travel Required: None Telecommuting Options: Remote Work Location: Any Location / Remote Additional Work Locations: Total Rewards at GDIT: Our benefits package for all US-based employees includes a variety of medical plan options, some with Health Savings Accounts, dental plan options, a vision plan, and a 401(k) plan offering the ability to contribute both pre and post-tax dollars up to the IRS annual limits and receive a company match. To encourage work/life balance, GDIT offers employees full flex work weeks where possible and a variety of paid time off plans, including vacation, sick and personal time, holidays, paid parental, military, bereavement and jury duty leave. GDIT typically provides new employees with 15 days of paid leave per calendar year to be used for vacations, personal business, and illness and an additional 10 paid holidays per year. Paid leave and paid holidays are prorated based on the employeeâ€™s date of hire. The GDIT Paid Family Leave program provides a total of up to 160 hours of paid leave in a rolling 12 month period for eligible employees. To ensure our employees are able to protect their income, other offerings such as short and long-term disability benefits, life, accidental death and dismemberment, personal accident, critical illness and business travel and accident insurance are provided or available. We regularly review our Total Rewards package to ensure our offerings are competitive and reflect what our employees have told us they value most. We are GDIT. A global technology and professional services company that delivers consulting, technology and mission services to every major agency across the U.S. government, defense and intelligence community. Our 30,000 experts extract the power of technology to create immediate value and deliver solutions at the edge of innovation. We operate across 50 countries worldwide, offering leading capabilities in digital modernization, AI/ML, Cloud, Cyber and application development. Together with our clients, we strive to create a safer, smarter world by harnessing the power of deep expertise and advanced technology. Join our Talent Community to stay up to date on our career opportunities and events at gdit.com/tc. Equal Opportunity Employer / Individuals with Disabilities / Protected Veterans